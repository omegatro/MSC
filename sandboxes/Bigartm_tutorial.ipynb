{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial based on Python2 code:\n",
    "https://docs.bigartm.org/en/latest/tutorials/python_tutorial.html\n",
    "\n",
    "- Known issues - the code may have to be adjusted to work with latest version of python3\n",
    "- artm.BatchVectorizer does not initialize dictionary if used with data_format='batches' - potentially solvable with https://docs.bigartm.org/en/latest/tutorials/python_userguide/loading_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install python=3.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bigartm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import artm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path='./data/', data_format='bow_uci',\n",
    "                                        collection_name='kos', target_folder='kos_batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = artm.LDA(num_topics=15, alpha=0.01, beta=0.001, cache_theta=True,\n",
    "               num_document_passes=5, dictionary=batch_vectorizer.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.sparsity_phi_last_value)\n",
    "print(lda.sparsity_theta_last_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.perplexity_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tokens = lda.get_top_tokens(num_tokens=10)\n",
    "for i, token_list in enumerate(top_tokens):\n",
    "     print('Topic #{0}: {1}'.format(i, token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = lda.phi_\n",
    "theta = lda.get_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import artm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vectorizer = None\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path='./data', data_format='bow_uci',\n",
    "                                            collection_name='kos', target_folder='kos')\n",
    "#else:\n",
    "    #Bugged - will not initialize dictionary\n",
    "    #print(2)\n",
    "    #batch_vectorizer = artm.BatchVectorizer(data_path='./kos',target_folder='kos', collection_name='kos', data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = batch_vectorizer.dictionary\n",
    "topic_names = ['topic_{}'.format(i) for i in range(15)]\n",
    "\n",
    "model_plsa = artm.ARTM(topic_names=topic_names, cache_theta=True,\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)])\n",
    "\n",
    "model_artm = artm.ARTM(topic_names=topic_names, cache_theta=True,\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)],\n",
    "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta',\n",
    "                                                                       tau=-0.15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plsa.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_plsa.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_plsa.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
    "                                            probability_mass_threshold=0.3))\n",
    "\n",
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
    "                                                  probability_mass_threshold=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
    "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plsa.num_document_passes = 1\n",
    "model_artm.num_document_passes = 1\n",
    "\n",
    "model_artm.initialize(dictionary = dictionary)\n",
    "model_plsa.initialize(dictionary = dictionary)\n",
    "\n",
    "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_measures(model_plsa, model_artm):\n",
    "    print('Sparsity Phi: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['SparsityPhiScore'].last_value,\n",
    "        model_artm.score_tracker['SparsityPhiScore'].last_value))\n",
    "\n",
    "    print('Sparsity Theta: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['SparsityThetaScore'].last_value,\n",
    "        model_artm.score_tracker['SparsityThetaScore'].last_value))\n",
    "\n",
    "    print('Kernel contrast: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['TopicKernelScore'].last_average_contrast,\n",
    "        model_artm.score_tracker['TopicKernelScore'].last_average_contrast))\n",
    "\n",
    "    print('Kernel purity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['TopicKernelScore'].last_average_purity,\n",
    "        model_artm.score_tracker['TopicKernelScore'].last_average_purity))\n",
    "\n",
    "    print('Perplexity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['PerplexityScore'].last_value,\n",
    "        model_artm.score_tracker['PerplexityScore'].last_value))\n",
    "\n",
    "    plt.plot(range(model_plsa.num_phi_updates),\n",
    "             model_plsa.score_tracker['PerplexityScore'].value, 'b--',\n",
    "             range(model_artm.num_phi_updates),\n",
    "             model_artm.score_tracker['PerplexityScore'].value, 'r--', linewidth=2)\n",
    "    plt.xlabel('Iterations count')\n",
    "    plt.ylabel('PLSA perp. (blue), ARTM perp. (red)')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_measures(model_plsa, model_artm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artm.regularizers['SparsePhi'].tau = -0.2\n",
    "model_artm.regularizers['SparseTheta'].tau = -0.2\n",
    "model_artm.regularizers['DecorrelatorPhi'].tau = 2.5e+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plsa.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_measures(model_plsa, model_artm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(model_plsa.num_phi_updates),\n",
    "         model_plsa.score_tracker['SparsityPhiScore'].value, 'b--',\n",
    "         range(model_artm.num_phi_updates),\n",
    "         model_artm.score_tracker['SparsityPhiScore'].value, 'r--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('PLSA Phi sp. (blue), ARTM Phi sp. (red)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(model_plsa.num_phi_updates),\n",
    "         model_plsa.score_tracker['SparsityThetaScore'].value, 'b--',\n",
    "         range(model_artm.num_phi_updates),\n",
    "         model_artm.score_tracker['SparsityThetaScore'].value, 'r--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('PLSA Theta sp. (blue), ARTM Theta sp. (red)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in model_plsa.topic_names:\n",
    "    print(topic_name + ': ')\n",
    "    print(model_plsa.score_tracker['TopTokensScore'].last_tokens[topic_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in model_artm.topic_names:\n",
    "    print(topic_name + ': ')\n",
    "    print(model_artm.score_tracker['TopTokensScore'].last_tokens[topic_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_artm.phi_)\n",
    "print(model_artm.get_theta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to load VW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vectorizer = artm.BatchVectorizer(data_path='../Data/bioit_set/bioit_set_1_vw.txt',\n",
    "                                        data_format='vowpal_wabbit',\n",
    "                                        target_folder='my_collection_batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = batch_vectorizer.dictionary\n",
    "topic_names = ['topic_{}'.format(i) for i in range(15)]\n",
    "\n",
    "model_plsa = artm.ARTM(topic_names=topic_names, cache_theta=True,\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)])\n",
    "\n",
    "model_artm = artm.ARTM(topic_names=topic_names, cache_theta=True,\n",
    "                       scores=[artm.PerplexityScore(name='PerplexityScore',\n",
    "                                                    dictionary=dictionary)],\n",
    "                       regularizers=[artm.SmoothSparseThetaRegularizer(name='SparseTheta',\n",
    "                                                                       tau=-0.15)])\n",
    "\n",
    "model_plsa.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_plsa.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_plsa.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
    "                                            probability_mass_threshold=0.3))\n",
    "\n",
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopicKernelScore(name='TopicKernelScore',\n",
    "                                                  probability_mass_threshold=0.3))\n",
    "\n",
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.1))\n",
    "model_artm.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1.5e+5))\n",
    "\n",
    "model_artm.__dict__\n",
    "\n",
    "model_plsa.num_document_passes = 1\n",
    "model_artm.num_document_passes = 1\n",
    "\n",
    "model_artm.initialize(dictionary = dictionary)\n",
    "model_plsa.initialize(dictionary = dictionary)\n",
    "\n",
    "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)\n",
    "\n",
    "def print_measures(model_plsa, model_artm):\n",
    "    print('Sparsity Phi: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['SparsityPhiScore'].last_value,\n",
    "        model_artm.score_tracker['SparsityPhiScore'].last_value))\n",
    "\n",
    "    print('Sparsity Theta: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['SparsityThetaScore'].last_value,\n",
    "        model_artm.score_tracker['SparsityThetaScore'].last_value))\n",
    "\n",
    "    print('Kernel contrast: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['TopicKernelScore'].last_average_contrast,\n",
    "        model_artm.score_tracker['TopicKernelScore'].last_average_contrast))\n",
    "\n",
    "    print('Kernel purity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['TopicKernelScore'].last_average_purity,\n",
    "        model_artm.score_tracker['TopicKernelScore'].last_average_purity))\n",
    "\n",
    "    print('Perplexity: {0:.3f} (PLSA) vs. {1:.3f} (ARTM)'.format(\n",
    "        model_plsa.score_tracker['PerplexityScore'].last_value,\n",
    "        model_artm.score_tracker['PerplexityScore'].last_value))\n",
    "\n",
    "    plt.plot(range(model_plsa.num_phi_updates),\n",
    "             model_plsa.score_tracker['PerplexityScore'].value, 'b--',\n",
    "             range(model_artm.num_phi_updates),\n",
    "             model_artm.score_tracker['PerplexityScore'].value, 'r--', linewidth=2)\n",
    "    plt.xlabel('Iterations count')\n",
    "    plt.ylabel('PLSA perp. (blue), ARTM perp. (red)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print_measures(model_plsa, model_artm)\n",
    "\n",
    "model_artm.regularizers['SparsePhi'].tau = -0.000002\n",
    "model_artm.regularizers['SparseTheta'].tau = -0.2\n",
    "model_artm.regularizers['DecorrelatorPhi'].tau = 2.5e+5\n",
    "\n",
    "model_plsa.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "model_artm.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=6))\n",
    "\n",
    "model_plsa.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=25)\n",
    "\n",
    "print_measures(model_plsa, model_artm)\n",
    "\n",
    "plt.plot(range(model_plsa.num_phi_updates),\n",
    "         model_plsa.score_tracker['SparsityPhiScore'].value, 'b--',\n",
    "         range(model_artm.num_phi_updates),\n",
    "         model_artm.score_tracker['SparsityPhiScore'].value, 'r--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('PLSA Phi sp. (blue), ARTM Phi sp. (red)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(model_plsa.num_phi_updates),\n",
    "         model_plsa.score_tracker['SparsityThetaScore'].value, 'b--',\n",
    "         range(model_artm.num_phi_updates),\n",
    "         model_artm.score_tracker['SparsityThetaScore'].value, 'r--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Iterations count')\n",
    "plt.ylabel('PLSA Theta sp. (blue), ARTM Theta sp. (red)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_project(linux)",
   "language": "python",
   "name": "msc_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
